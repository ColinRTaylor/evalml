{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
=======
>>>>>>> main
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Text Data with EvalML\n",
    "\n",
    "In this demo, we will show you how to use EvalML to build models which use text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import AutoMLSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will be utilizing a dataset of SMS text messages, some of which are categorized as spam, and others which are not (\"ham\"). This dataset is originally from [Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset), but modified to produce a slightly more even distribution of spam to ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "2  WINNER!! As a valued network customer you have...\n",
       "3  Had your mobile 11 months or more? U R entitle...\n",
       "4  SIX chances to win CASH! From 100 to 20,000 po..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "input_data = urlopen('https://featurelabs-static.s3.amazonaws.com/spam_text_messages_modified.csv')\n",
    "data = pd.read_csv(input_data)\n",
    "\n",
    "X = data.drop(['Category'], axis=1)\n",
    "y = data['Category']\n",
    "\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ham vs spam distribution of the data is 3:1, so any machine learning model must get above 75% [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) in order to perform better than a trivial baseline model which simply classifies everything as ham. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.750084\n",
       "spam    0.249916\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for best pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the results of the pipeline creation and optimization process, we will save some of our data as a holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, problem_type='binary', test_size=0.2, random_seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EvalML uses [Woodwork](https://woodwork.alteryx.com/en/stable/) to automatically detect which columns are text columns, so you can run search normally, as you would if there was no text data. We can print out the logical type of the `Message` column and assert that it is indeed inferred as a natural language column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Physical Type</th>\n",
       "      <th>Logical Type</th>\n",
       "      <th>Semantic Tag(s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Message</th>\n",
       "      <td>string</td>\n",
       "      <td>NaturalLanguage</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Physical Type     Logical Type Semantic Tag(s)\n",
       "Column                                                \n",
       "Message        string  NaturalLanguage              []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ww.types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the spam/ham labels are binary, we will use `AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary')`. When we call `.search()`, the search for the best pipeline will begin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 1 batches for a total of 9 pipelines. \n",
      "Allowed model families: decision_tree, random_forest, catboost, lightgbm, xgboost, linear_model, extra_trees\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd0c3c4a6fe4d3d90228455cbec3299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: (1/9) Mode Baseline Binary Classification P... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 8.638\n",
      "Batch 1: (2/9) Decision Tree Classifier w/ Text Feat... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.802\n",
      "High coefficient of variation (cv >= 0.2) within cross validation scores. Decision Tree Classifier w/ Text Featurization Component may not perform as estimated on unseen data.\n",
      "Batch 1: (3/9) LightGBM Classifier w/ Text Featuriza... Elapsed:00:10\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.215\n",
      "High coefficient of variation (cv >= 0.2) within cross validation scores. LightGBM Classifier w/ Text Featurization Component may not perform as estimated on unseen data.\n",
      "Batch 1: (4/9) Extra Trees Classifier w/ Text Featur... Elapsed:00:19\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.252\n",
      "High coefficient of variation (cv >= 0.2) within cross validation scores. Extra Trees Classifier w/ Text Featurization Component may not perform as estimated on unseen data.\n",
      "Batch 1: (5/9) Elastic Net Classifier w/ Text Featur... Elapsed:00:28\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.543\n",
      "Batch 1: (6/9) CatBoost Classifier w/ Text Featuriza... Elapsed:00:35\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.526\n",
      "Batch 1: (7/9) XGBoost Classifier w/ Text Featurizat... Elapsed:00:43\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.179\n",
      "High coefficient of variation (cv >= 0.2) within cross validation scores. XGBoost Classifier w/ Text Featurization Component may not perform as estimated on unseen data.\n",
      "Batch 1: (8/9) Random Forest Classifier w/ Text Feat... Elapsed:00:51\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.155\n",
      "High coefficient of variation (cv >= 0.2) within cross validation scores. Random Forest Classifier w/ Text Featurization Component may not perform as estimated on unseen data.\n",
      "Batch 1: (9/9) Logistic Regression Classifier w/ Tex... Elapsed:00:59\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.214\n",
      "High coefficient of variation (cv >= 0.2) within cross validation scores. Logistic Regression Classifier w/ Text Featurization Component + Standard Scaler may not perform as estimated on unseen data.\n",
      "\n",
      "Search finished after 01:08            \n",
      "Best pipeline: Random Forest Classifier w/ Text Featurization Component\n",
      "Best pipeline Log Loss Binary: 0.154849\n"
     ]
    }
   ],
   "source": [
    "automl = AutoMLSearch(X_train=X_train, y_train=y_train,\n",
    "                      problem_type='binary',\n",
    "                      max_batches=1,\n",
    "                      optimize_thresholds=True)\n",
    "\n",
    "automl.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View rankings and select pipeline\n",
    "\n",
    "Once the fitting process is done, we can see all of the pipelines that were searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>percent_better_than_baseline</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Random Forest Classifier w/ Text Featurization...</td>\n",
       "      <td>0.154849</td>\n",
       "      <td>0.110302</td>\n",
       "      <td>98.207418</td>\n",
       "      <td>True</td>\n",
       "      <td>{'Random Forest Classifier': {'n_estimators': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>XGBoost Classifier w/ Text Featurization Compo...</td>\n",
       "      <td>0.178639</td>\n",
       "      <td>0.113254</td>\n",
       "      <td>97.932010</td>\n",
       "      <td>True</td>\n",
       "      <td>{'XGBoost Classifier': {'eta': 0.1, 'max_depth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Logistic Regression Classifier w/ Text Featuri...</td>\n",
       "      <td>0.214011</td>\n",
       "      <td>0.165624</td>\n",
       "      <td>97.522538</td>\n",
       "      <td>True</td>\n",
       "      <td>{'Logistic Regression Classifier': {'penalty':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM Classifier w/ Text Featurization Comp...</td>\n",
       "      <td>0.214580</td>\n",
       "      <td>0.136260</td>\n",
       "      <td>97.515944</td>\n",
       "      <td>True</td>\n",
       "      <td>{'LightGBM Classifier': {'boosting_type': 'gbd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Extra Trees Classifier w/ Text Featurization C...</td>\n",
       "      <td>0.252206</td>\n",
       "      <td>0.216198</td>\n",
       "      <td>97.080377</td>\n",
       "      <td>True</td>\n",
       "      <td>{'Extra Trees Classifier': {'n_estimators': 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost Classifier w/ Text Featurization Comp...</td>\n",
       "      <td>0.526403</td>\n",
       "      <td>0.512717</td>\n",
       "      <td>93.906174</td>\n",
       "      <td>False</td>\n",
       "      <td>{'CatBoost Classifier': {'n_estimators': 10, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Elastic Net Classifier w/ Text Featurization C...</td>\n",
       "      <td>0.542803</td>\n",
       "      <td>0.529152</td>\n",
       "      <td>93.716325</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Elastic Net Classifier': {'alpha': 0.5, 'l1_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree Classifier w/ Text Featurization...</td>\n",
       "      <td>0.801766</td>\n",
       "      <td>0.555179</td>\n",
       "      <td>90.718481</td>\n",
       "      <td>True</td>\n",
       "      <td>{'Decision Tree Classifier': {'criterion': 'gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Mode Baseline Binary Classification Pipeline</td>\n",
       "      <td>8.638305</td>\n",
       "      <td>8.623860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Baseline Classifier': {'strategy': 'mode'}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      pipeline_name     score  \\\n",
       "0   7  Random Forest Classifier w/ Text Featurization...  0.154849   \n",
       "1   6  XGBoost Classifier w/ Text Featurization Compo...  0.178639   \n",
       "2   8  Logistic Regression Classifier w/ Text Featuri...  0.214011   \n",
       "3   2  LightGBM Classifier w/ Text Featurization Comp...  0.214580   \n",
       "4   3  Extra Trees Classifier w/ Text Featurization C...  0.252206   \n",
       "5   5  CatBoost Classifier w/ Text Featurization Comp...  0.526403   \n",
       "6   4  Elastic Net Classifier w/ Text Featurization C...  0.542803   \n",
       "7   1  Decision Tree Classifier w/ Text Featurization...  0.801766   \n",
       "8   0       Mode Baseline Binary Classification Pipeline  8.638305   \n",
       "\n",
       "   validation_score  percent_better_than_baseline  high_variance_cv  \\\n",
       "0          0.110302                     98.207418              True   \n",
       "1          0.113254                     97.932010              True   \n",
       "2          0.165624                     97.522538              True   \n",
       "3          0.136260                     97.515944              True   \n",
       "4          0.216198                     97.080377              True   \n",
       "5          0.512717                     93.906174             False   \n",
       "6          0.529152                     93.716325             False   \n",
       "7          0.555179                     90.718481              True   \n",
       "8          8.623860                      0.000000             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'Random Forest Classifier': {'n_estimators': ...  \n",
       "1  {'XGBoost Classifier': {'eta': 0.1, 'max_depth...  \n",
       "2  {'Logistic Regression Classifier': {'penalty':...  \n",
       "3  {'LightGBM Classifier': {'boosting_type': 'gbd...  \n",
       "4  {'Extra Trees Classifier': {'n_estimators': 10...  \n",
       "5  {'CatBoost Classifier': {'n_estimators': 10, '...  \n",
       "6  {'Elastic Net Classifier': {'alpha': 0.5, 'l1_...  \n",
       "7  {'Decision Tree Classifier': {'criterion': 'gi...  \n",
       "8      {'Baseline Classifier': {'strategy': 'mode'}}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the best pipeline we can call `automl.best_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = automl.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe pipeline\n",
    "\n",
    "You can get more details about any pipeline, including how it performed on other objective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "* Random Forest Classifier w/ Text Featurization Component *\n",
      "************************************************************\n",
      "\n",
      "Problem Type: binary\n",
      "Model Family: Random Forest\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Text Featurization Component\n",
      "2. Random Forest Classifier\n",
      "\t * n_estimators : 100\n",
      "\t * max_depth : 6\n",
      "\t * n_jobs : -1\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for binary problems.\n",
      "Total training time (including CV): 8.5 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "             Log Loss Binary  MCC Binary   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary # Training # Validation\n",
      "0                      0.110       0.895 0.987      0.938 0.921                     0.942            0.961     1594.0        797.0\n",
      "1                      0.144       0.854 0.980      0.919 0.888                     0.917            0.946     1594.0        797.0\n",
      "2                      0.210       0.783 0.962      0.839 0.837                     0.891            0.918     1594.0        797.0\n",
      "mean                   0.155       0.844 0.977      0.899 0.882                     0.917            0.942          -            -\n",
      "std                    0.051       0.057 0.013      0.052 0.042                     0.026            0.022          -            -\n",
      "coef of var            0.326       0.067 0.013      0.058 0.048                     0.028            0.023          -            -\n"
     ]
    }
   ],
   "source": [
    "automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"383pt\" height=\"85pt\"\n",
       " viewBox=\"0.00 0.00 383.00 85.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 81)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-81 379,-81 379,4 -4,4\"/>\n",
       "<!-- Text Featurization Component -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Text Featurization Component</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-15 0,-62 184,-62 184,-15 0,-15\"/>\n",
       "<text text-anchor=\"middle\" x=\"92\" y=\"-46.8\" font-family=\"Times,serif\" font-size=\"14.00\">Text Featurization Component</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-39 184,-39 \"/>\n",
       "</g>\n",
       "<!-- Random Forest Classifier -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Random Forest Classifier</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"220,-0.5 220,-76.5 375,-76.5 375,-0.5 220,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.5\" y=\"-61.3\" font-family=\"Times,serif\" font-size=\"14.00\">Random Forest Classifier</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"220,-53.5 375,-53.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"228\" y=\"-38.3\" font-family=\"Times,serif\" font-size=\"14.00\">n_estimators : 100</text>\n",
       "<text text-anchor=\"start\" x=\"228\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\">max_depth : 6</text>\n",
       "<text text-anchor=\"start\" x=\"228\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">n_jobs : &#45;1</text>\n",
       "</g>\n",
       "<!-- Text Featurization Component&#45;&gt;Random Forest Classifier -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Text Featurization Component&#45;&gt;Random Forest Classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.23,-38.5C184.23,-38.5 209.69,-38.5 209.69,-38.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"209.69,-42 219.69,-38.5 209.69,-35 209.69,-42\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe5f8029370>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that there is a `Text Featurization Component` as the first step in the pipeline. The Woodwork `DataTable` passed in to AutoML search recognizes that `'Message'` is a text column, and converts this text into numerical values that can be handled by the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can score the pipeline on the holdout data using the core objectives for binary classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Binary: 0.9732441471571907\n"
     ]
    }
   ],
   "source": [
    "scores = best_pipeline.score(X_holdout, y_holdout,  objectives=evalml.objectives.get_core_objectives('binary'))\n",
    "print(f'Accuracy Binary: {scores[\"Accuracy Binary\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model performs relatively well on this dataset, even on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why encode text this way?\n",
    "\n",
    "To demonstrate the importance of text-specific modeling, let's train a model with the same dataset, without letting `AutoMLSearch` detect the text column. We can change this by explicitly setting the data type of the `'Message'` column in Woodwork to `Categorical` using the utility method `infer_feature_types`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.utils import infer_feature_types\n",
    "X = infer_feature_types(X, {'Message': 'Categorical'})\n",
    "X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, problem_type='binary', test_size=0.2, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 1 batches for a total of 9 pipelines. \n",
      "Allowed model families: decision_tree, random_forest, catboost, lightgbm, xgboost, linear_model, extra_trees\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9205c875a31645a1a45955ca5a98aeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: (1/9) Mode Baseline Binary Classification P... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 8.638\n",
      "Batch 1: (2/9) Decision Tree Classifier w/ Imputer +... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.561\n",
      "Batch 1: (3/9) LightGBM Classifier w/ Imputer + One ... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.562\n",
      "Batch 1: (4/9) Extra Trees Classifier w/ Imputer + O... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.561\n",
      "Batch 1: (5/9) Elastic Net Classifier w/ Imputer + O... Elapsed:00:01\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.563\n",
      "Batch 1: (6/9) CatBoost Classifier w/ Imputer           Elapsed:00:01\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.622\n",
      "Batch 1: (7/9) XGBoost Classifier w/ Imputer + One H... Elapsed:00:02\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.562\n",
      "Batch 1: (8/9) Random Forest Classifier w/ Imputer +... Elapsed:00:02\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.561\n",
      "Batch 1: (9/9) Logistic Regression Classifier w/ Imp... Elapsed:00:03\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.561\n",
      "\n",
      "Search finished after 00:04            \n",
      "Best pipeline: Logistic Regression Classifier w/ Imputer + One Hot Encoder + Standard Scaler\n",
      "Best pipeline Log Loss Binary: 0.560554\n"
     ]
    }
   ],
   "source": [
    "automl_no_text = AutoMLSearch(X_train=X_train, y_train=y_train,\n",
    "                              problem_type='binary',\n",
    "                              max_batches=1,\n",
    "                              optimize_thresholds=True)\n",
    "\n",
    "automl_no_text.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we can look at the rankings and pick the best pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>percent_better_than_baseline</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Logistic Regression Classifier w/ Imputer + On...</td>\n",
       "      <td>0.560554</td>\n",
       "      <td>0.558141</td>\n",
       "      <td>93.510838</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree Classifier w/ Imputer + One Hot ...</td>\n",
       "      <td>0.561003</td>\n",
       "      <td>0.558148</td>\n",
       "      <td>93.505636</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Random Forest Classifier w/ Imputer + One Hot ...</td>\n",
       "      <td>0.561179</td>\n",
       "      <td>0.559141</td>\n",
       "      <td>93.503593</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Extra Trees Classifier w/ Imputer + One Hot En...</td>\n",
       "      <td>0.561247</td>\n",
       "      <td>0.559029</td>\n",
       "      <td>93.502811</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>XGBoost Classifier w/ Imputer + One Hot Encoder</td>\n",
       "      <td>0.562197</td>\n",
       "      <td>0.561991</td>\n",
       "      <td>93.491811</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM Classifier w/ Imputer + One Hot Encoder</td>\n",
       "      <td>0.562451</td>\n",
       "      <td>0.561991</td>\n",
       "      <td>93.488872</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Elastic Net Classifier w/ Imputer + One Hot En...</td>\n",
       "      <td>0.562556</td>\n",
       "      <td>0.562070</td>\n",
       "      <td>93.487658</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost Classifier w/ Imputer</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.622812</td>\n",
       "      <td>92.794318</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Mode Baseline Binary Classification Pipeline</td>\n",
       "      <td>8.638305</td>\n",
       "      <td>8.623860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Baseline Classifier': {'strategy': 'mode'}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      pipeline_name     score  \\\n",
       "0   8  Logistic Regression Classifier w/ Imputer + On...  0.560554   \n",
       "1   1  Decision Tree Classifier w/ Imputer + One Hot ...  0.561003   \n",
       "2   7  Random Forest Classifier w/ Imputer + One Hot ...  0.561179   \n",
       "3   3  Extra Trees Classifier w/ Imputer + One Hot En...  0.561247   \n",
       "4   6    XGBoost Classifier w/ Imputer + One Hot Encoder  0.562197   \n",
       "5   2   LightGBM Classifier w/ Imputer + One Hot Encoder  0.562451   \n",
       "6   4  Elastic Net Classifier w/ Imputer + One Hot En...  0.562556   \n",
       "7   5                     CatBoost Classifier w/ Imputer  0.622449   \n",
       "8   0       Mode Baseline Binary Classification Pipeline  8.638305   \n",
       "\n",
       "   validation_score  percent_better_than_baseline  high_variance_cv  \\\n",
       "0          0.558141                     93.510838             False   \n",
       "1          0.558148                     93.505636             False   \n",
       "2          0.559141                     93.503593             False   \n",
       "3          0.559029                     93.502811             False   \n",
       "4          0.561991                     93.491811             False   \n",
       "5          0.561991                     93.488872             False   \n",
       "6          0.562070                     93.487658             False   \n",
       "7          0.622812                     92.794318             False   \n",
       "8          8.623860                      0.000000             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "1  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "2  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "3  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "4  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "5  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "6  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "7  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "8      {'Baseline Classifier': {'strategy': 'mode'}}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_no_text.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline_no_text = automl_no_text.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, changing the data type of the text column removed the `Text Featurization Component` from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"819pt\" height=\"130pt\"\n",
       " viewBox=\"0.00 0.00 819.00 130.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 126)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-126 815,-126 815,4 -4,4\"/>\n",
       "<!-- Imputer -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Imputer</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-15.5 0,-106.5 260,-106.5 260,-15.5 0,-15.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"130\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">Imputer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-83.5 260,-83.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_impute_strategy : most_frequent</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_impute_strategy : mean</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-38.3\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_fill_value : None</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_fill_value : None</text>\n",
       "</g>\n",
       "<!-- One Hot Encoder -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>One Hot Encoder</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"296,-0.5 296,-121.5 458,-121.5 458,-0.5 296,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"377\" y=\"-106.3\" font-family=\"Times,serif\" font-size=\"14.00\">One Hot Encoder</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"296,-98.5 458,-98.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"304\" y=\"-83.3\" font-family=\"Times,serif\" font-size=\"14.00\">top_n : 10</text>\n",
       "<text text-anchor=\"start\" x=\"304\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">features_to_encode : None</text>\n",
       "<text text-anchor=\"start\" x=\"304\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">categories : None</text>\n",
       "<text text-anchor=\"start\" x=\"304\" y=\"-38.3\" font-family=\"Times,serif\" font-size=\"14.00\">drop : if_binary</text>\n",
       "<text text-anchor=\"start\" x=\"304\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\">handle_unknown : ignore</text>\n",
       "<text text-anchor=\"start\" x=\"304\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">handle_missing : error</text>\n",
       "</g>\n",
       "<!-- Imputer&#45;&gt;One Hot Encoder -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Imputer&#45;&gt;One Hot Encoder</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M260.01,-61C260.01,-61 285.89,-61 285.89,-61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"285.89,-64.5 295.89,-61 285.89,-57.5 285.89,-64.5\"/>\n",
       "</g>\n",
       "<!-- Standard Scaler -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Standard Scaler</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"494,-37.5 494,-84.5 596,-84.5 596,-37.5 494,-37.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"545\" y=\"-69.3\" font-family=\"Times,serif\" font-size=\"14.00\">Standard Scaler</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"494,-61.5 596,-61.5 \"/>\n",
       "</g>\n",
       "<!-- One Hot Encoder&#45;&gt;Standard Scaler -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>One Hot Encoder&#45;&gt;Standard Scaler</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M458.05,-61C458.05,-61 483.54,-61 483.54,-61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"483.54,-64.5 493.54,-61 483.54,-57.5 483.54,-64.5\"/>\n",
       "</g>\n",
       "<!-- Logistic Regression Classifier -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Logistic Regression Classifier</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"632,-8 632,-114 811,-114 811,-8 632,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"721.5\" y=\"-98.8\" font-family=\"Times,serif\" font-size=\"14.00\">Logistic Regression Classifier</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"632,-91 811,-91 \"/>\n",
       "<text text-anchor=\"start\" x=\"640\" y=\"-75.8\" font-family=\"Times,serif\" font-size=\"14.00\">penalty : l2</text>\n",
       "<text text-anchor=\"start\" x=\"640\" y=\"-60.8\" font-family=\"Times,serif\" font-size=\"14.00\">C : 1.00</text>\n",
       "<text text-anchor=\"start\" x=\"640\" y=\"-45.8\" font-family=\"Times,serif\" font-size=\"14.00\">n_jobs : &#45;1</text>\n",
       "<text text-anchor=\"start\" x=\"640\" y=\"-30.8\" font-family=\"Times,serif\" font-size=\"14.00\">multi_class : auto</text>\n",
       "<text text-anchor=\"start\" x=\"640\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">solver : lbfgs</text>\n",
       "</g>\n",
       "<!-- Standard Scaler&#45;&gt;Logistic Regression Classifier -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Standard Scaler&#45;&gt;Logistic Regression Classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M596.05,-61C596.05,-61 621.98,-61 621.98,-61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"621.98,-64.5 631.98,-61 621.98,-57.5 621.98,-64.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe619652430>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline_no_text.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************************\n",
      "* Logistic Regression Classifier w/ Imputer + One Hot Encoder + Standard Scaler *\n",
      "*********************************************************************************\n",
      "\n",
      "Problem Type: binary\n",
      "Model Family: Linear\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : mean\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "2. One Hot Encoder\n",
      "\t * top_n : 10\n",
      "\t * features_to_encode : None\n",
      "\t * categories : None\n",
      "\t * drop : if_binary\n",
      "\t * handle_unknown : ignore\n",
      "\t * handle_missing : error\n",
      "3. Standard Scaler\n",
      "4. Logistic Regression Classifier\n",
      "\t * penalty : l2\n",
      "\t * C : 1.0\n",
      "\t * n_jobs : -1\n",
      "\t * multi_class : auto\n",
      "\t * solver : lbfgs\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for binary problems.\n",
      "Total training time (including CV): 1.4 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "             Log Loss Binary  MCC Binary   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary # Training # Validation\n",
      "0                      0.558       0.061 0.508      1.000 0.010                     0.503            0.752     1594.0        797.0\n",
      "1                      0.561       0.000 0.503      0.000 0.000                     0.500            0.750     1594.0        797.0\n",
      "2                      0.563       0.000 0.503      0.000 0.000                     0.500            0.749     1594.0        797.0\n",
      "mean                   0.561       0.020 0.504      0.333 0.003                     0.501            0.750          -            -\n",
      "std                    0.002       0.035 0.003      0.577 0.006                     0.001            0.001          -            -\n",
      "coef of var            0.004       1.732 0.006      1.732 1.732                     0.003            0.002          -            -\n"
     ]
    }
   ],
   "source": [
    "automl_no_text.describe_pipeline(automl_no_text.rankings.iloc[0][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Binary: 0.7525083612040134\n"
     ]
    }
   ],
   "source": [
    "# get standard performance metrics on holdout data\n",
    "scores = best_pipeline_no_text.score(X_holdout, y_holdout, objectives=evalml.objectives.get_core_objectives('binary'))\n",
    "print(f'Accuracy Binary: {scores[\"Accuracy Binary\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the `Text Featurization Component`, the `'Message'` column was treated as a categorical column, and therefore the conversion of this text to numerical features happened in the `One Hot Encoder`. The best pipeline encoded the top 10 most frequent \"categories\" of these texts, meaning 10 text messages were one-hot encoded and all the others were dropped. Clearly, this removed almost all of the information from the dataset, as we can see the `best_pipeline_no_text` performs very similarly to randomly guessing \"ham\" in every case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}