{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Text Data with EvalML\n",
    "\n",
    "In this demo, we will show you how to use EvalML to build models which use text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import AutoMLSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will be utilizing a dataset of SMS text messages, some of which are categorized as spam, and others which are not (\"ham\"). This dataset is originally from [Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset), but modified to produce a slightly more even distribution of spam to ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "2  WINNER!! As a valued network customer you have...\n",
       "3  Had your mobile 11 months or more? U R entitle...\n",
       "4  SIX chances to win CASH! From 100 to 20,000 po..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "input_data = urlopen('https://featurelabs-static.s3.amazonaws.com/spam_text_messages_modified.csv')\n",
    "data = pd.read_csv(input_data)[:750]\n",
    "\n",
    "X = data.drop(['Category'], axis=1)\n",
    "y = data['Category']\n",
    "\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ham vs spam distribution of the data is 3:1, so any machine learning model must get above 75% [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) in order to perform better than a trivial baseline model which simply classifies everything as ham. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    0.593333\n",
       "ham     0.406667\n",
       "Name: Category, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to properly utilize Woodwork's 'Natural Language' typing, we need to pass this argument in during initialization. Otherwise, this will be treated as an 'Unknown' type and dropped in the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.ww.init(logical_types={\"Message\": \"NaturalLanguage\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for best pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the results of the pipeline creation and optimization process, we will save some of our data as a holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, problem_type='binary', test_size=0.2, random_seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EvalML uses [Woodwork](https://woodwork.alteryx.com/en/stable/) to automatically detect which columns are text columns, so you can run search normally, as you would if there was no text data. We can print out the logical type of the `Message` column and assert that it is indeed inferred as a natural language column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Physical Type</th>\n",
       "      <th>Logical Type</th>\n",
       "      <th>Semantic Tag(s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Message</th>\n",
       "      <td>string</td>\n",
       "      <td>NaturalLanguage</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "        Physical Type     Logical Type Semantic Tag(s)\n",
       "Column                                                \n",
       "Message        string  NaturalLanguage              []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ww"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the spam/ham labels are binary, we will use `AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary')`. When we call `.search()`, the search for the best pipeline will begin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:evalml.automl.automl_algorithm.iterative_algorithm.verbose:allowed_estimators set to ['Decision Tree Classifier', 'LightGBM Classifier', 'Extra Trees Classifier', 'Elastic Net Classifier', 'CatBoost Classifier', 'XGBoost Classifier', 'Random Forest Classifier', 'Logistic Regression Classifier']\n",
      "DEBUG:evalml.automl.automl_algorithm.iterative_algorithm.verbose:allowed_pipelines set to ['Elastic Net Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler', 'Logistic Regression Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler', 'XGBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'LightGBM Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'CatBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'Decision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'Extra Trees Classifier w/ Label Encoder + Natural Language Featurizer + Imputer']\n",
      "DEBUG:evalml.automl.automl_algorithm.iterative_algorithm.verbose:allowed_model_families set to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 pipelines ready for search.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_algorithm.iterative_algorithm.verbose:8 pipelines ready for search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Beginning pipeline search *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:* Beginning pipeline search *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:*****************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for Log Loss Binary. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Optimizing for Log Loss Binary. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower score is better.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Lower score is better.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SequentialEngine to train and score pipelines.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Using SequentialEngine to train and score pipelines.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching up to 1 batches for a total of 9 pipelines. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Searching up to 1 batches for a total of 9 pipelines. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed model families: linear_model, linear_model, xgboost, lightgbm, catboost, random_forest, decision_tree, extra_trees\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Allowed model families: linear_model, linear_model, xgboost, lightgbm, catboost, random_forest, decision_tree, extra_trees\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496baaf9f8e145689114a6fe8a7b4748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode Baseline Binary Classification Pipeline:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Mode Baseline Binary Classification Pipeline:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.135)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 13.988\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.135)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 13.988\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.135)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 14.161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 14.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 14.046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Evaluating Batch Number 1 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:* Evaluating Batch Number 1 *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:*****************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Elastic Net Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.253)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.310\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.196)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.248\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.460)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Logistic Regression Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.267)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.302\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.638)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.241\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.460)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:XGBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.295)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.222\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.769)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.159\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.365)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:LightGBM Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.368)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.258\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.897)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.168\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.232)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:CatBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.489)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.586\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.484)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.580\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.504)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.398)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.206\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.595)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.171\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.429)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Decision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.183)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 1.384\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.626)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 1.000\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.019)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 2.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 1.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 1.698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHigh coefficient of variation (cv >= 0.5) within cross validation scores.\n",
      "\tDecision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer may not perform as estimated on unseen data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evalml.automl.automl_search.verbose:\tHigh coefficient of variation (cv >= 0.5) within cross validation scores.\n",
      "\tDecision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer may not perform as estimated on unseen data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Extra Trees Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.421)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.285\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.252)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.244\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.376)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search finished after 00:38            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n",
      "Search finished after 00:38            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pipeline: Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Best pipeline: Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pipeline Log Loss Binary: 0.209360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Best pipeline Log Loss Binary: 0.209360\n"
     ]
    }
   ],
   "source": [
    "automl = AutoMLSearch(X_train=X_train, y_train=y_train,\n",
    "                      problem_type='binary',\n",
    "                      max_batches=1,\n",
    "                      optimize_thresholds=True,\n",
    "                      verbose=True)\n",
    "\n",
    "automl.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View rankings and select pipeline\n",
    "\n",
    "Once the fitting process is done, we can see all of the pipelines that were searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>search_order</th>\n",
       "      <th>mean_cv_score</th>\n",
       "      <th>standard_deviation_cv_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>percent_better_than_baseline</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Random Forest Classifier w/ Label Encoder + Na...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.209360</td>\n",
       "      <td>0.040523</td>\n",
       "      <td>0.209360</td>\n",
       "      <td>98.509448</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost Classifier w/ Label Encoder + Natural ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252028</td>\n",
       "      <td>0.111184</td>\n",
       "      <td>0.252028</td>\n",
       "      <td>98.205663</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Extra Trees Classifier w/ Label Encoder + Natu...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.268202</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.268202</td>\n",
       "      <td>98.090516</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM Classifier w/ Label Encoder + Natural...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.269452</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.269452</td>\n",
       "      <td>98.081612</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression Classifier w/ Label Encode...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.324151</td>\n",
       "      <td>0.096452</td>\n",
       "      <td>0.324151</td>\n",
       "      <td>97.692183</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Elastic Net Classifier w/ Label Encoder + Natu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.329292</td>\n",
       "      <td>0.092042</td>\n",
       "      <td>0.329292</td>\n",
       "      <td>97.655582</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost Classifier w/ Label Encoder + Natural...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.584976</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.584976</td>\n",
       "      <td>95.835212</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Decision Tree Classifier w/ Label Encoder + Na...</td>\n",
       "      <td>7</td>\n",
       "      <td>1.697547</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>1.697547</td>\n",
       "      <td>87.914177</td>\n",
       "      <td>True</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Mode Baseline Binary Classification Pipeline</td>\n",
       "      <td>0</td>\n",
       "      <td>14.045769</td>\n",
       "      <td>0.099705</td>\n",
       "      <td>14.045769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      pipeline_name  search_order  \\\n",
       "0   6  Random Forest Classifier w/ Label Encoder + Na...             6   \n",
       "1   3  XGBoost Classifier w/ Label Encoder + Natural ...             3   \n",
       "2   8  Extra Trees Classifier w/ Label Encoder + Natu...             8   \n",
       "3   4  LightGBM Classifier w/ Label Encoder + Natural...             4   \n",
       "4   2  Logistic Regression Classifier w/ Label Encode...             2   \n",
       "5   1  Elastic Net Classifier w/ Label Encoder + Natu...             1   \n",
       "6   5  CatBoost Classifier w/ Label Encoder + Natural...             5   \n",
       "7   7  Decision Tree Classifier w/ Label Encoder + Na...             7   \n",
       "8   0       Mode Baseline Binary Classification Pipeline             0   \n",
       "\n",
       "   mean_cv_score  standard_deviation_cv_score  validation_score  \\\n",
       "0       0.209360                     0.040523          0.209360   \n",
       "1       0.252028                     0.111184          0.252028   \n",
       "2       0.268202                     0.021350          0.268202   \n",
       "3       0.269452                     0.108020          0.269452   \n",
       "4       0.324151                     0.096452          0.324151   \n",
       "5       0.329292                     0.092042          0.329292   \n",
       "6       0.584976                     0.004147          0.584976   \n",
       "7       1.697547                     0.895859          1.697547   \n",
       "8      14.045769                     0.099705         14.045769   \n",
       "\n",
       "   percent_better_than_baseline  high_variance_cv  \\\n",
       "0                     98.509448             False   \n",
       "1                     98.205663             False   \n",
       "2                     98.090516             False   \n",
       "3                     98.081612             False   \n",
       "4                     97.692183             False   \n",
       "5                     97.655582             False   \n",
       "6                     95.835212             False   \n",
       "7                     87.914177              True   \n",
       "8                      0.000000             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "1  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "2  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "3  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "4  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "5  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "6  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "7  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "8  {'Label Encoder': {'positive_label': None}, 'B...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the best pipeline we can call `automl.best_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = automl.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe pipeline\n",
    "\n",
    "You can get more details about any pipeline, including how it performed on other objective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:\n",
      "*************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:* Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:*************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem Type: binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:Problem Type: binary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Family: Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:Model Family: Random Forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:Pipeline Steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:==============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Label Encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.component_graph.describe:1. Label Encoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * positive_label : None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * positive_label : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Natural Language Featurizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.component_graph.describe:2. Natural Language Featurizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Imputer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.component_graph.describe:3. Imputer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * categorical_impute_strategy : most_frequent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * categorical_impute_strategy : most_frequent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * numeric_impute_strategy : mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * numeric_impute_strategy : mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * categorical_fill_value : None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * categorical_fill_value : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * numeric_fill_value : None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * numeric_fill_value : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Random Forest Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.component_graph.describe:4. Random Forest Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * n_estimators : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * n_estimators : 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * max_depth : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * max_depth : 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * n_jobs : -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * n_jobs : -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for binary problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:Training for binary problems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time (including CV): 4.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:Total training time (including CV): 4.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:Cross Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Log Loss Binary  MCC Binary  Gini   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary # Training # Validation\n",
      "0                      0.206       0.876 0.953 0.977      0.916 0.927                     0.940            0.940        400          200\n",
      "1                      0.171       0.855 0.977 0.988      0.947 0.910                     0.921            0.930        400          200\n",
      "2                      0.252       0.783 0.924 0.962      0.877 0.871                     0.891            0.895        400          200\n",
      "mean                   0.209       0.838 0.951 0.976      0.913 0.903                     0.917            0.922          -            -\n",
      "std                    0.041       0.049 0.026 0.013      0.035 0.029                     0.025            0.024          -            -\n",
      "coef of var            0.194       0.059 0.028 0.014      0.038 0.032                     0.027            0.026          -            -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:             Log Loss Binary  MCC Binary  Gini   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary # Training # Validation\n",
      "0                      0.206       0.876 0.953 0.977      0.916 0.927                     0.940            0.940        400          200\n",
      "1                      0.171       0.855 0.977 0.988      0.947 0.910                     0.921            0.930        400          200\n",
      "2                      0.252       0.783 0.924 0.962      0.877 0.871                     0.891            0.895        400          200\n",
      "mean                   0.209       0.838 0.951 0.976      0.913 0.903                     0.917            0.922          -            -\n",
      "std                    0.041       0.049 0.026 0.013      0.035 0.029                     0.025            0.024          -            -\n",
      "coef of var            0.194       0.059 0.028 0.014      0.038 0.032                     0.027            0.026          -            -\n"
     ]
    }
   ],
   "source": [
    "automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.49.1 (20210923.0004)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"928pt\" height=\"130pt\"\n",
       " viewBox=\"0.00 0.00 928.00 129.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 125.5)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-125.5 924,-125.5 924,4 -4,4\"/>\n",
       "<!-- Label Encoder -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Label Encoder</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"72,-16.5 72,-62.5 208,-62.5 208,-16.5 72,-16.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"140\" y=\"-47.3\" font-family=\"Times,serif\" font-size=\"14.00\">Label Encoder</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"72,-39.5 208,-39.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"80\" y=\"-24.3\" font-family=\"Times,serif\" font-size=\"14.00\">positive_label : None</text>\n",
       "</g>\n",
       "<!-- Natural Language Featurizer -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Natural Language Featurizer</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"244,-68 244,-115 421,-115 421,-68 244,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"332.5\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\">Natural Language Featurizer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244,-92 421,-92 \"/>\n",
       "</g>\n",
       "<!-- Label Encoder&#45;&gt;Natural Language Featurizer -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>Label Encoder&#45;&gt;Natural Language Featurizer</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M208.16,-57.83C217.07,-60.26 226.33,-62.79 235.6,-65.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"234.69,-68.7 245.25,-67.96 236.53,-61.95 234.69,-68.7\"/>\n",
       "</g>\n",
       "<!-- Imputer -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Imputer</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"457,-30 457,-121 724,-121 724,-30 457,-30\"/>\n",
       "<text text-anchor=\"middle\" x=\"590.5\" y=\"-105.8\" font-family=\"Times,serif\" font-size=\"14.00\">Imputer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"457,-98 724,-98 \"/>\n",
       "<text text-anchor=\"start\" x=\"465\" y=\"-82.8\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_impute_strategy : most_frequent</text>\n",
       "<text text-anchor=\"start\" x=\"465\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_impute_strategy : mean</text>\n",
       "<text text-anchor=\"start\" x=\"465\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_fill_value : None</text>\n",
       "<text text-anchor=\"start\" x=\"465\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_fill_value : None</text>\n",
       "</g>\n",
       "<!-- Label Encoder&#45;&gt;Imputer -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Label Encoder&#45;&gt;Imputer</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M208.09,-43.43C264.84,-46.91 348.3,-52.37 421,-58.5 429.32,-59.2 437.86,-59.96 446.48,-60.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"446.35,-64.25 456.63,-61.68 446.99,-57.28 446.35,-64.25\"/>\n",
       "</g>\n",
       "<!-- Random Forest Classifier -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Random Forest Classifier</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"760,-0.5 760,-76.5 920,-76.5 920,-0.5 760,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"840\" y=\"-61.3\" font-family=\"Times,serif\" font-size=\"14.00\">Random Forest Classifier</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"760,-53.5 920,-53.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"768\" y=\"-38.3\" font-family=\"Times,serif\" font-size=\"14.00\">n_estimators : 100</text>\n",
       "<text text-anchor=\"start\" x=\"768\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\">max_depth : 6</text>\n",
       "<text text-anchor=\"start\" x=\"768\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">n_jobs : &#45;1</text>\n",
       "</g>\n",
       "<!-- Label Encoder&#45;&gt;Random Forest Classifier -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>Label Encoder&#45;&gt;Random Forest Classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M208.44,-32.49C317.13,-22.27 537.72,-6.01 724,-20.5 732.33,-21.15 740.96,-22.06 749.59,-23.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"749.33,-26.62 759.69,-24.44 750.23,-19.68 749.33,-26.62\"/>\n",
       "</g>\n",
       "<!-- Natural Language Featurizer&#45;&gt;Imputer -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Natural Language Featurizer&#45;&gt;Imputer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M421.24,-86.02C429.46,-85.5 437.93,-84.97 446.48,-84.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"446.8,-87.93 456.56,-83.81 446.36,-80.94 446.8,-87.93\"/>\n",
       "</g>\n",
       "<!-- Imputer&#45;&gt;Random Forest Classifier -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Imputer&#45;&gt;Random Forest Classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M724.31,-55.65C732.95,-54.35 741.53,-53.07 749.88,-51.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"750.58,-55.26 759.95,-50.32 749.54,-48.33 750.58,-55.26\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-91.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Label Encoder -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X&#45;&gt;Label Encoder</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.69,-84.7C45.63,-79.96 61.01,-73.3 76.61,-66.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78,-69.75 85.78,-62.56 75.21,-63.33 78,-69.75\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Natural Language Featurizer -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>X&#45;&gt;Natural Language Featurizer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M36.25,-91.5C73.26,-91.5 162.7,-91.5 233.51,-91.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.81,-95 243.81,-91.5 233.81,-88 233.81,-95\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-37.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-33.8\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;Label Encoder -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>y&#45;&gt;Label Encoder</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M36.19,-37.79C43.36,-37.91 52.23,-38.05 61.73,-38.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61.75,-41.71 71.81,-38.38 61.87,-34.71 61.75,-41.71\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x10c0c9f70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that there is a `Natural Language Featurizer` as the first step in the pipeline. AutoMLSearch uses the woodwork accessor to recognize that `'Message'` is a text column, and converts this text into numerical values that can be handled by the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can score the pipeline on the holdout data using the core objectives for binary classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Binary: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "scores = best_pipeline.score(X_holdout, y_holdout,  objectives=evalml.objectives.get_core_objectives('binary'))\n",
    "print(f'Accuracy Binary: {scores[\"Accuracy Binary\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model performs relatively well on this dataset, even on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the Natural Language Featurizer do?\n",
    "\n",
    "Machine learning models cannot handle non-numeric data. Any text must be broken down into numeric features that provide useful information about that text. The Natural Natural Language Featurizer first normalizes your text by removing any punctuation and other non-alphanumeric characters and converting any capital letters to lowercase. From there, it passes the text into [featuretools](https://www.featuretools.com/)' [nlp_primitives](https://docs.featuretools.com/en/v0.16.0/api_reference.html#natural-language-processing-primitives) `dfs` search, resulting in several informative features that replace the original column in your dataset: Diversity Score, Mean Characters per Word, Polarity Score, LSA (Latent Semantic Analysis), Number of Characters, and Number of Words.\n",
    "\n",
    "**Diversity Score** is the ratio of unique words to total words.\n",
    "\n",
    "**Mean Characters per Word** is the average number of letters in each word.\n",
    "\n",
    "**Polarity Score** is a prediction of how \"polarized\" the text is, on a scale from -1 (extremely negative) to 1 (extremely positive).\n",
    "\n",
    "**Latent Semantic Analysis** is an abstract representation of how important each word is with respect to the entire text, reduced down into two values per text. While the other text features are each a single column, this feature adds two columns to your data, `LSA(column_name)[0]` and `LSA(column_name)[1]`.\n",
    "\n",
    "**Number of Characters** is the number of characters in the text.\n",
    "\n",
    "**Number of Words** is the number of words in the text.\n",
    "\n",
    "Let's see what this looks like with our spam/ham example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Label Encoder': ['Message'],\n",
       " 'Natural Language Featurizer': ['Message'],\n",
       " 'Imputer': ['DIVERSITY_SCORE(Message)',\n",
       "  'MEAN_CHARACTERS_PER_WORD(Message)',\n",
       "  'NUM_CHARACTERS(Message)',\n",
       "  'NUM_WORDS(Message)',\n",
       "  'POLARITY_SCORE(Message)',\n",
       "  'LSA(Message)[0]',\n",
       "  'LSA(Message)[1]'],\n",
       " 'Random Forest Classifier': ['DIVERSITY_SCORE(Message)',\n",
       "  'MEAN_CHARACTERS_PER_WORD(Message)',\n",
       "  'NUM_CHARACTERS(Message)',\n",
       "  'NUM_WORDS(Message)',\n",
       "  'POLARITY_SCORE(Message)',\n",
       "  'LSA(Message)[0]',\n",
       "  'LSA(Message)[1]']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline.input_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the Natural Language Featurizer takes in a single \"Message\" column, but then the next component in the pipeline, the Imputer, receives five columns of input. These five columns are the result of featurizing the text-type \"Message\" column. Most importantly, these featurized columns are what ends up passed in to the estimator.\n",
    "\n",
    "If the dataset had any non-text columns, those would be left alone by this process. If the dataset had more than one text column, each would be broken into these five feature columns independently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The features, more directly\n",
    "\n",
    "Rather than just checking the new column names, let's examine the output of this component directly. We can see this by running the component on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_language_featurizer = evalml.pipelines.components.NaturalLanguageFeaturizer()\n",
    "X_featurized = natural_language_featurizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the input data to the output from the Natural Language Featurizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Sunshine Hols. To claim ur med holiday send a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>Yup ü not comin :-(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>Hello hun how ru? Its here by the way. Im good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>I tagged MY friends that you seemed to count a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>What happened to our yo date?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Message\n",
       "296  Sunshine Hols. To claim ur med holiday send a ...\n",
       "652                                Yup ü not comin :-(\n",
       "526  Hello hun how ru? Its here by the way. Im good...\n",
       "571  I tagged MY friends that you seemed to count a...\n",
       "472                      What happened to our yo date?"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIVERSITY_SCORE(Message)</th>\n",
       "      <th>MEAN_CHARACTERS_PER_WORD(Message)</th>\n",
       "      <th>NUM_CHARACTERS(Message)</th>\n",
       "      <th>NUM_WORDS(Message)</th>\n",
       "      <th>POLARITY_SCORE(Message)</th>\n",
       "      <th>LSA(Message)[0]</th>\n",
       "      <th>LSA(Message)[1]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.344828</td>\n",
       "      <td>154.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.150556</td>\n",
       "      <td>-0.072443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017340</td>\n",
       "      <td>-0.005411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>143.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.169954</td>\n",
       "      <td>0.022670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.8</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.144713</td>\n",
       "      <td>0.036799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.109373</td>\n",
       "      <td>-0.042754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DIVERSITY_SCORE(Message)  MEAN_CHARACTERS_PER_WORD(Message)  \\\n",
       "296                       1.0                           4.344828   \n",
       "652                       1.0                           3.000000   \n",
       "526                       1.0                           3.363636   \n",
       "571                       0.8                           4.083333   \n",
       "472                       1.0                           3.833333   \n",
       "\n",
       "     NUM_CHARACTERS(Message)  NUM_WORDS(Message)  POLARITY_SCORE(Message)  \\\n",
       "296                    154.0                29.0                    0.003   \n",
       "652                     16.0                 5.0                    0.000   \n",
       "526                    143.0                33.0                    0.162   \n",
       "571                     60.0                12.0                    0.681   \n",
       "472                     28.0                 6.0                    0.000   \n",
       "\n",
       "     LSA(Message)[0]  LSA(Message)[1]  \n",
       "296         0.150556        -0.072443  \n",
       "652         0.017340        -0.005411  \n",
       "526         0.169954         0.022670  \n",
       "571         0.144713         0.036799  \n",
       "472         0.109373        -0.042754  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_featurized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numeric values now represent important information about the original text that the estimator at the end of the pipeline can successfully use to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why encode text this way?\n",
    "\n",
    "To demonstrate the importance of text-specific modeling, let's train a model with the same dataset, without letting `AutoMLSearch` detect the text column. We can change this by explicitly setting the data type of the `'Message'` column in Woodwork to `Categorical` using the utility method `infer_feature_types`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.utils import infer_feature_types\n",
    "X = infer_feature_types(X, {'Message': 'Categorical'})\n",
    "X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, problem_type='binary', test_size=0.2, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_algorithm.iterative_algorithm.verbose:Generating pipelines to search over...\n",
      "DEBUG:evalml.automl.automl_algorithm.iterative_algorithm.verbose:allowed_estimators set to ['Decision Tree Classifier', 'LightGBM Classifier', 'Extra Trees Classifier', 'Elastic Net Classifier', 'CatBoost Classifier', 'XGBoost Classifier', 'Random Forest Classifier', 'Logistic Regression Classifier']\n",
      "DEBUG:evalml.automl.automl_algorithm.iterative_algorithm.verbose:allowed_pipelines set to ['Elastic Net Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler', 'Logistic Regression Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler', 'XGBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'LightGBM Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'CatBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'Decision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer', 'Extra Trees Classifier w/ Label Encoder + Natural Language Featurizer + Imputer']\n",
      "DEBUG:evalml.automl.automl_algorithm.iterative_algorithm.verbose:allowed_model_families set to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 pipelines ready for search.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_algorithm.iterative_algorithm.verbose:8 pipelines ready for search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Beginning pipeline search *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:* Beginning pipeline search *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:*****************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for Log Loss Binary. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Optimizing for Log Loss Binary. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower score is better.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Lower score is better.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SequentialEngine to train and score pipelines.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Using SequentialEngine to train and score pipelines.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching up to 1 batches for a total of 9 pipelines. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Searching up to 1 batches for a total of 9 pipelines. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed model families: linear_model, linear_model, xgboost, lightgbm, catboost, random_forest, decision_tree, extra_trees\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Allowed model families: linear_model, linear_model, xgboost, lightgbm, catboost, random_forest, decision_tree, extra_trees\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8534de25f2472d9f5b09d771888973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode Baseline Binary Classification Pipeline:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Mode Baseline Binary Classification Pipeline:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.135)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 13.988\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.135)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 13.988\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.135)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 14.161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 14.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 14.046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Evaluating Batch Number 1 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:* Evaluating Batch Number 1 *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:*****************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Elastic Net Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.253)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.310\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.196)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.248\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.460)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Logistic Regression Classifier w/ Label Encoder + Natural Language Featurizer + Imputer + Standard Scaler:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.267)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.302\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.638)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.241\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.460)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:XGBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.295)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.222\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.769)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.159\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.365)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:LightGBM Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.368)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.258\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.897)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.168\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.232)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:CatBoost Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.489)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.586\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.484)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.580\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.504)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.398)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.206\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.595)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.171\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.429)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Decision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.183)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 1.384\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.626)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 1.000\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.019)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 2.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 1.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 1.698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHigh coefficient of variation (cv >= 0.5) within cross validation scores.\n",
      "\tDecision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer may not perform as estimated on unseen data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evalml.automl.automl_search.verbose:\tHigh coefficient of variation (cv >= 0.5) within cross validation scores.\n",
      "\tDecision Tree Classifier w/ Label Encoder + Natural Language Featurizer + Imputer may not perform as estimated on unseen data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Extra Trees Classifier w/ Label Encoder + Natural Language Featurizer + Imputer:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStarting cross validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tStarting cross validation\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 0\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Optimal threshold found (0.421)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 0: Log Loss Binary score: 0.285\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 1\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Optimal threshold found (0.252)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 1: Log Loss Binary score: 0.244\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\tTraining and scoring on fold 2\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: starting training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: finished training\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Optimal threshold found (0.376)\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Scoring trained pipeline\n",
      "DEBUG:evalml.automl.automl_search.verbose:\t\t\tFold 2: Log Loss Binary score: 0.275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFinished cross validation - mean Log Loss Binary: 0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\tFinished cross validation - mean Log Loss Binary: 0.268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search finished after 00:34            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:\n",
      "Search finished after 00:34            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pipeline: Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Best pipeline: Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pipeline Log Loss Binary: 0.209360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.verbose:Best pipeline Log Loss Binary: 0.209360\n"
     ]
    }
   ],
   "source": [
    "automl_no_text = AutoMLSearch(X_train=X_train, y_train=y_train,\n",
    "                              problem_type='binary',\n",
    "                              max_batches=1,\n",
    "                              optimize_thresholds=True,\n",
    "                              verbose=True)\n",
    "\n",
    "automl_no_text.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we can look at the rankings and pick the best pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>search_order</th>\n",
       "      <th>mean_cv_score</th>\n",
       "      <th>standard_deviation_cv_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>percent_better_than_baseline</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Random Forest Classifier w/ Label Encoder + Na...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.209360</td>\n",
       "      <td>0.040523</td>\n",
       "      <td>0.209360</td>\n",
       "      <td>98.509448</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost Classifier w/ Label Encoder + Natural ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252028</td>\n",
       "      <td>0.111184</td>\n",
       "      <td>0.252028</td>\n",
       "      <td>98.205663</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Extra Trees Classifier w/ Label Encoder + Natu...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.268202</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.268202</td>\n",
       "      <td>98.090516</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LightGBM Classifier w/ Label Encoder + Natural...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.269452</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.269452</td>\n",
       "      <td>98.081612</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression Classifier w/ Label Encode...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.324151</td>\n",
       "      <td>0.096452</td>\n",
       "      <td>0.324151</td>\n",
       "      <td>97.692183</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Elastic Net Classifier w/ Label Encoder + Natu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.329292</td>\n",
       "      <td>0.092042</td>\n",
       "      <td>0.329292</td>\n",
       "      <td>97.655582</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>CatBoost Classifier w/ Label Encoder + Natural...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.584976</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.584976</td>\n",
       "      <td>95.835212</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Decision Tree Classifier w/ Label Encoder + Na...</td>\n",
       "      <td>7</td>\n",
       "      <td>1.697547</td>\n",
       "      <td>0.895859</td>\n",
       "      <td>1.697547</td>\n",
       "      <td>87.914177</td>\n",
       "      <td>True</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Mode Baseline Binary Classification Pipeline</td>\n",
       "      <td>0</td>\n",
       "      <td>14.045769</td>\n",
       "      <td>0.099705</td>\n",
       "      <td>14.045769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Label Encoder': {'positive_label': None}, 'B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      pipeline_name  search_order  \\\n",
       "0   6  Random Forest Classifier w/ Label Encoder + Na...             6   \n",
       "1   3  XGBoost Classifier w/ Label Encoder + Natural ...             3   \n",
       "2   8  Extra Trees Classifier w/ Label Encoder + Natu...             8   \n",
       "3   4  LightGBM Classifier w/ Label Encoder + Natural...             4   \n",
       "4   2  Logistic Regression Classifier w/ Label Encode...             2   \n",
       "5   1  Elastic Net Classifier w/ Label Encoder + Natu...             1   \n",
       "6   5  CatBoost Classifier w/ Label Encoder + Natural...             5   \n",
       "7   7  Decision Tree Classifier w/ Label Encoder + Na...             7   \n",
       "8   0       Mode Baseline Binary Classification Pipeline             0   \n",
       "\n",
       "   mean_cv_score  standard_deviation_cv_score  validation_score  \\\n",
       "0       0.209360                     0.040523          0.209360   \n",
       "1       0.252028                     0.111184          0.252028   \n",
       "2       0.268202                     0.021350          0.268202   \n",
       "3       0.269452                     0.108020          0.269452   \n",
       "4       0.324151                     0.096452          0.324151   \n",
       "5       0.329292                     0.092042          0.329292   \n",
       "6       0.584976                     0.004147          0.584976   \n",
       "7       1.697547                     0.895859          1.697547   \n",
       "8      14.045769                     0.099705         14.045769   \n",
       "\n",
       "   percent_better_than_baseline  high_variance_cv  \\\n",
       "0                     98.509448             False   \n",
       "1                     98.205663             False   \n",
       "2                     98.090516             False   \n",
       "3                     98.081612             False   \n",
       "4                     97.692183             False   \n",
       "5                     97.655582             False   \n",
       "6                     95.835212             False   \n",
       "7                     87.914177              True   \n",
       "8                      0.000000             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "1  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "2  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "3  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "4  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "5  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "6  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "7  {'Label Encoder': {'positive_label': None}, 'I...  \n",
       "8  {'Label Encoder': {'positive_label': None}, 'B...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_no_text.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline_no_text = automl_no_text.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, changing the data type of the text column removed the `Natural Language Featurizer` from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.49.1 (20210923.0004)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"928pt\" height=\"130pt\"\n",
       " viewBox=\"0.00 0.00 928.00 129.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 125.5)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-125.5 924,-125.5 924,4 -4,4\"/>\n",
       "<!-- Label Encoder -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Label Encoder</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"72,-16.5 72,-62.5 208,-62.5 208,-16.5 72,-16.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"140\" y=\"-47.3\" font-family=\"Times,serif\" font-size=\"14.00\">Label Encoder</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"72,-39.5 208,-39.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"80\" y=\"-24.3\" font-family=\"Times,serif\" font-size=\"14.00\">positive_label : None</text>\n",
       "</g>\n",
       "<!-- Natural Language Featurizer -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Natural Language Featurizer</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"244,-68 244,-115 421,-115 421,-68 244,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"332.5\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\">Natural Language Featurizer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244,-92 421,-92 \"/>\n",
       "</g>\n",
       "<!-- Label Encoder&#45;&gt;Natural Language Featurizer -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>Label Encoder&#45;&gt;Natural Language Featurizer</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M208.16,-57.83C217.07,-60.26 226.33,-62.79 235.6,-65.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"234.69,-68.7 245.25,-67.96 236.53,-61.95 234.69,-68.7\"/>\n",
       "</g>\n",
       "<!-- Imputer -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Imputer</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"457,-30 457,-121 724,-121 724,-30 457,-30\"/>\n",
       "<text text-anchor=\"middle\" x=\"590.5\" y=\"-105.8\" font-family=\"Times,serif\" font-size=\"14.00\">Imputer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"457,-98 724,-98 \"/>\n",
       "<text text-anchor=\"start\" x=\"465\" y=\"-82.8\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_impute_strategy : most_frequent</text>\n",
       "<text text-anchor=\"start\" x=\"465\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_impute_strategy : mean</text>\n",
       "<text text-anchor=\"start\" x=\"465\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_fill_value : None</text>\n",
       "<text text-anchor=\"start\" x=\"465\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_fill_value : None</text>\n",
       "</g>\n",
       "<!-- Label Encoder&#45;&gt;Imputer -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Label Encoder&#45;&gt;Imputer</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M208.09,-43.43C264.84,-46.91 348.3,-52.37 421,-58.5 429.32,-59.2 437.86,-59.96 446.48,-60.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"446.35,-64.25 456.63,-61.68 446.99,-57.28 446.35,-64.25\"/>\n",
       "</g>\n",
       "<!-- Random Forest Classifier -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Random Forest Classifier</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"760,-0.5 760,-76.5 920,-76.5 920,-0.5 760,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"840\" y=\"-61.3\" font-family=\"Times,serif\" font-size=\"14.00\">Random Forest Classifier</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"760,-53.5 920,-53.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"768\" y=\"-38.3\" font-family=\"Times,serif\" font-size=\"14.00\">n_estimators : 100</text>\n",
       "<text text-anchor=\"start\" x=\"768\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\">max_depth : 6</text>\n",
       "<text text-anchor=\"start\" x=\"768\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">n_jobs : &#45;1</text>\n",
       "</g>\n",
       "<!-- Label Encoder&#45;&gt;Random Forest Classifier -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>Label Encoder&#45;&gt;Random Forest Classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M208.44,-32.49C317.13,-22.27 537.72,-6.01 724,-20.5 732.33,-21.15 740.96,-22.06 749.59,-23.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"749.33,-26.62 759.69,-24.44 750.23,-19.68 749.33,-26.62\"/>\n",
       "</g>\n",
       "<!-- Natural Language Featurizer&#45;&gt;Imputer -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Natural Language Featurizer&#45;&gt;Imputer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M421.24,-86.02C429.46,-85.5 437.93,-84.97 446.48,-84.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"446.8,-87.93 456.56,-83.81 446.36,-80.94 446.8,-87.93\"/>\n",
       "</g>\n",
       "<!-- Imputer&#45;&gt;Random Forest Classifier -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Imputer&#45;&gt;Random Forest Classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M724.31,-55.65C732.95,-54.35 741.53,-53.07 749.88,-51.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"750.58,-55.26 759.95,-50.32 749.54,-48.33 750.58,-55.26\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-91.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Label Encoder -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X&#45;&gt;Label Encoder</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.69,-84.7C45.63,-79.96 61.01,-73.3 76.61,-66.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78,-69.75 85.78,-62.56 75.21,-63.33 78,-69.75\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Natural Language Featurizer -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>X&#45;&gt;Natural Language Featurizer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M36.25,-91.5C73.26,-91.5 162.7,-91.5 233.51,-91.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.81,-95 243.81,-91.5 233.81,-88 233.81,-95\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-37.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"18\" y=\"-33.8\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;Label Encoder -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>y&#45;&gt;Label Encoder</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M36.19,-37.79C43.36,-37.91 52.23,-38.05 61.73,-38.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61.75,-41.71 71.81,-38.38 61.87,-34.71 61.75,-41.71\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x14dd2b670>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline_no_text.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:\n",
      "*************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:* Random Forest Classifier w/ Label Encoder + Natural Language Featurizer + Imputer *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:*************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem Type: binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:Problem Type: binary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Family: Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:Model Family: Random Forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:Pipeline Steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.pipeline_base.describe:==============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Label Encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.component_graph.describe:1. Label Encoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * positive_label : None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * positive_label : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Natural Language Featurizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.component_graph.describe:2. Natural Language Featurizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Imputer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.component_graph.describe:3. Imputer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * categorical_impute_strategy : most_frequent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * categorical_impute_strategy : most_frequent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * numeric_impute_strategy : mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * numeric_impute_strategy : mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * categorical_fill_value : None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * categorical_fill_value : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * numeric_fill_value : None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * numeric_fill_value : None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Random Forest Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.component_graph.describe:4. Random Forest Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * n_estimators : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * n_estimators : 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * max_depth : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * max_depth : 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t * n_jobs : -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.pipelines.components.component_base.describe:\t * n_jobs : -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for binary problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:Training for binary problems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time (including CV): 3.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:Total training time (including CV): 3.9 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:Cross Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Log Loss Binary  MCC Binary  Gini   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary # Training # Validation\n",
      "0                      0.206       0.876 0.953 0.977      0.916 0.927                     0.940            0.940        400          200\n",
      "1                      0.171       0.855 0.977 0.988      0.947 0.910                     0.921            0.930        400          200\n",
      "2                      0.252       0.783 0.924 0.962      0.877 0.871                     0.891            0.895        400          200\n",
      "mean                   0.209       0.838 0.951 0.976      0.913 0.903                     0.917            0.922          -            -\n",
      "std                    0.041       0.049 0.026 0.013      0.035 0.029                     0.025            0.024          -            -\n",
      "coef of var            0.194       0.059 0.028 0.014      0.038 0.032                     0.027            0.026          -            -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:evalml.automl.automl_search.describe_pipeline:             Log Loss Binary  MCC Binary  Gini   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary # Training # Validation\n",
      "0                      0.206       0.876 0.953 0.977      0.916 0.927                     0.940            0.940        400          200\n",
      "1                      0.171       0.855 0.977 0.988      0.947 0.910                     0.921            0.930        400          200\n",
      "2                      0.252       0.783 0.924 0.962      0.877 0.871                     0.891            0.895        400          200\n",
      "mean                   0.209       0.838 0.951 0.976      0.913 0.903                     0.917            0.922          -            -\n",
      "std                    0.041       0.049 0.026 0.013      0.035 0.029                     0.025            0.024          -            -\n",
      "coef of var            0.194       0.059 0.028 0.014      0.038 0.032                     0.027            0.026          -            -\n"
     ]
    }
   ],
   "source": [
    "automl_no_text.describe_pipeline(automl_no_text.rankings.iloc[0][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Binary: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# get standard performance metrics on holdout data\n",
    "scores = best_pipeline_no_text.score(X_holdout, y_holdout, objectives=evalml.objectives.get_core_objectives('binary'))\n",
    "print(f'Accuracy Binary: {scores[\"Accuracy Binary\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the `Natural Language Featurizer`, the `'Message'` column was treated as a categorical column, and therefore the conversion of this text to numerical features happened in the `One Hot Encoder`. The best pipeline encoded the top 10 most frequent \"categories\" of these texts, meaning 10 text messages were one-hot encoded and all the others were dropped. Clearly, this removed almost all of the information from the dataset, as we can see the `best_pipeline_no_text` performs very similarly to randomly guessing \"ham\" in every case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv-evalml",
   "language": "python",
   "name": "virtualenv-evalml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
