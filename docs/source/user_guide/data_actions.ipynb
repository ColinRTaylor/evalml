{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with EvalML\n",
    "\n",
    "EvalML streamlines the creation and implementation of machine learning models for tabular data. One of the many features it offers is data checks, which are geared towards determining the health of the data before we train a model on it. In our default data checks, we have the following checks:\n",
    "- HighlyNullDataCheck: Checks whether the rows or columns are highly null\n",
    "- IDColumnsDataCheck: Checks for columns that could be ID columns\n",
    "- TargetLeakageDataCheck: Checks if any of the input features have high association with the associated targets\n",
    "- InvalidTargetDataCheck: Checks if there are null or other invalid features in the targets\n",
    "- NoVarianceDataCheck: Checks if any targets or features have no variance\n",
    "- NaturalLanguageNaNDataCheck: Checks if any natural language columns have missing data\n",
    "- DateTimeNaNDataCheck: Checks if any datetime columns have missing data\n",
    "\n",
    "EvalML has additional data checks which can be accessed through the API, and the documentation for that is [here](https://evalml.alteryx.com/en/stable/api_index.html#data-checks), with steps to use them [here](https://evalml.alteryx.com/en/stable/user_guide/data_checks.html). We will walk through example usage of the default data checks that EvalML provides.\n",
    "\n",
    "\n",
    "First, we import the necessary requirements to demonstrate these checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import woodwork as ww\n",
    "import pandas as pd\n",
    "from evalml import AutoMLSearch\n",
    "from evalml.demos import load_fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the X data. EvalML uses the [Woodwork](https://woodwork.alteryx.com/en/stable/) library to represent this data. The demo data that EvalML returns is of Woodwork's DataTable and DataColumn types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_fraud(n_rows=1000)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is already clean and compatible with EvalML's ``AutoMLSearch``. In order to demonstrate the default data checks that EvalML can do, we add some noise and unhealthy data to this distribution. These changes we include are:\n",
    "- A row of null values\n",
    "- A column of mostly null values (0.5% non-null)\n",
    "- An ID column\n",
    "- A column with low/no variance\n",
    "- A missing target value\n",
    "\n",
    "Note that these aren't all of the scenarios that the default data checks can catch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with no variance in the data\n",
    "X['no variance'] = [1 for _ in range(X.shape[0])]\n",
    "\n",
    "# add an ID column\n",
    "X['id'] = [i+1 for i in range(X.shape[0])]\n",
    "\n",
    "# make row 1 all nan values\n",
    "X.iloc[1] = [np.nan] * X.shape[1]\n",
    "\n",
    "# add a column with 99.5% null values\n",
    "X['mostly_nulls'] = [np.nan] * 995 + [i for i in range(5)]\n",
    "\n",
    "# make one of the target values null\n",
    "y[990] = None\n",
    "\n",
    "# since we changed the data, let's reinitialize the woodwork datatable\n",
    "X.ww.init()\n",
    "y = ww.init_series(y)\n",
    "# Let's take another look at the new X data\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call AutoMLSearch on this data, we will see that the search fails. This is because there are a lot of issues with the input data (issues that we added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(X_train=X, y_train=y, problem_type='binary')\n",
    "try:\n",
    "    automl.search()\n",
    "except ValueError as e:\n",
    "    print(\"Search errored out! Message received is: {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the search function provided in EvalML to determine what potential health issues our data has. Note that this `search` function is a public method available through `evalml.automl` and is different from the search function of the `AutoMLSearch` class in EvalML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.automl import search\n",
    "results = search(X, y, problem_type='binary')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return value of the `search` function above is a tuple. The first element is the `AutoMLSearch` object if it runs (None otherwise), and the second is a dictionary of potential warnings and errors that the default data checks find in the passed-in `X` and `y` data. We can look at the `actions` key of the dictionary in order to see what how we can fix and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]['actions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that there are 4 action tasks that we can take to clean the data. 3 of the tasks ask us to drop a row or column in the features, while 1 task asks us to impute the target value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first action states to drop the first row\n",
    "X.drop(1, axis=0, inplace=True)\n",
    "# we must also drop this for y since we are removing its associated feature input\n",
    "y.drop(index=1, inplace=True)\n",
    "\n",
    "print(\"The new length of X is {} and y is {}\".format(len(X),len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'mostly_nulls' column from X, which is the second action item\n",
    "X.drop('mostly_nulls', axis=1, inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address the null in targets, which is the third action item\n",
    "y.fillna(False, inplace=True)\n",
    "y.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can drop the 'no variance' column, which is the final action item\n",
    "X.drop('no variance', axis=1, inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's reinitialize the dataframe using Woodwork and try the search again\n",
    "X.ww.init()\n",
    "results = search(X, y, problem_type='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this time, we do get an `AutoMLSearch` object returned us, as well as an empty dictionary of warnings and errors. We can use the `AutoMLSearch` object as needed, and we can see that the resulting warning dictionary is empty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = results[0]\n",
    "aml.rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings_dic = results[1]\n",
    "warnings_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, we aim to provide a helper function to allow users to quickly clean the data by taking in the list of actions and creating an appropriate pipeline of transformers to alter the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}